{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1LETojNHOzmflXlVmYYv6rf90ZYYa4Woy","authorship_tag":"ABX9TyPpOnkXEhf5JFguy8VCUQzN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### **Preprocessing**\n","**# Preprocess 'utterance' column**\n","- Step 1. Tokenization -> split()\n","- Step 2. Word Embedding -> pretrained Glove\n","- Step 3. Create 'Vectorization' column\n","- Step 4. Save .csv file"],"metadata":{"id":"pVDd9eBhterX"}},{"cell_type":"markdown","source":["#### Sentence Vectorization"],"metadata":{"id":"BYn7_JZgyddB"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# GloVe 임베딩 로드\n","def load_glove_model(glove_file_path):\n","    glove_model = {}\n","    with open(glove_file_path, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            values = line.split()\n","            word = values[0]\n","            vector = np.array(values[1:], dtype='float32')\n","            glove_model[word] = vector\n","    return glove_model\n","\n","# 문장을 단어로 토큰화하여 GloVe 벡터로 변환하는 함수 정의\n","def sentence_to_vector(sentence, glove_model):\n","    tokens = sentence.split()\n","    vectorized_tokens = [glove_model[token.lower()] for token in tokens if token.lower() in glove_model]\n","    if vectorized_tokens:\n","        # 각 단어 벡터를 평균하여 문장 벡터 생성\n","        sentence_vector = np.mean(vectorized_tokens, axis=0)\n","    else:\n","        # 단어 벡터가 없는 경우 기본적인 임베딩 값 반환\n","        sentence_vector = np.zeros_like(next(iter(glove_model.values())))\n","    return sentence_vector\n","\n","# CSV 파일 경로\n","csv_file_path = \"/content/drive/MyDrive/2024-1 graph-mining/final_project/sample_cont_280.csv\"\n","\n","# GloVe 파일 경로\n","glove_file_path = \"/content/drive/MyDrive/2024-1 graph-mining/final_project/glove.6B.300d.txt\"\n","glove_model = load_glove_model(glove_file_path)\n","\n","# CSV 파일 읽기\n","data = pd.read_csv(csv_file_path)\n","\n","# 'utterance' 열의 각 문장을 GloVe를 사용하여 토큰화하고 벡터화하여 'Vectorization' 열에 저장\n","data['Vectorization'] = data['utterance'].apply(lambda x: sentence_to_vector(x, glove_model))\n","\n","# 결과 출력\n","print(data.head())\n","\n","# 수정된 데이터프레임을 CSV 파일로 저장\n","output_csv_file_path = \"/content/drive/MyDrive/2024-1 graph-mining/final_project/Contrastive_with_vectors_280.csv\"\n","data.to_csv(output_csv_file_path, index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1eINfDWBIdS9","executionInfo":{"status":"ok","timestamp":1713528228987,"user_tz":-540,"elapsed":42319,"user":{"displayName":"Yubeen Lee","userId":"01212685212812926822"}},"outputId":"4a789cd8-235c-47aa-b3b7-fc2df27aa0f3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["       emotion                                          utterance  \\\n","0  contentment  this reminds me of my house as a child growing up   \n","1      sadness  The face and body of the person in painting lo...   \n","2      sadness                      This lady looks sad and lost.   \n","3         fear  there is only really one line in the picture a...   \n","4        anger  The woman will not allow black people to enter...   \n","\n","              art_style                             painting  repetition  \\\n","0               Realism                        do not called          13   \n","1         Impressionism                      boy in sea foam           9   \n","2         Expressionism       germaine survage with earrings          10   \n","3  Color_Field_Painting                            the voice          15   \n","4         Impressionism  helene rouart in her father s study           4   \n","\n","               artist  year                                      Vectorization  \n","0  pyotr konchalovsky  1947  [-0.23660432, 0.023783177, 0.0031121785, -0.13...  \n","1   joaquã­n sorolla  1900  [-0.099079795, 0.06223135, -0.021821667, -0.30...  \n","2   amedeo modigliani  1918  [-0.0553888, 0.023891795, 0.08666819, -0.33695...  \n","3      barnett newman  1950  [-0.16806385, 0.1246284, -0.068070605, -0.1362...  \n","4         edgar degas  1886  [-0.1755427, 0.12994654, -0.16544211, -0.21736...  \n"]}]},{"cell_type":"markdown","source":["#### Calculate Cosine Similarity"],"metadata":{"id":"5Skb5bgHwMs2"}},{"cell_type":"code","source":["from numpy import dot\n","from numpy.linalg import norm\n","\n","def cosine_similarity(vec1, vec2):\n","    if norm(vec1) > 0 and norm(vec2) > 0:\n","        return dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n","    else:\n","        return 0  # 두 벡터 중 하나라도 영 벡터인 경우 유사도는 0\n","\n","# 첫 번째 문장과 두 번째 문장의 벡터 가져오기\n","vector1 = data['Vectorization'][0]\n","vector2 = data['Vectorization'][1]\n","\n","# 코사인 유사도 계산\n","similarity = cosine_similarity(vector1, vector2)\n","print(\"첫 번째 문장과 두 번째 문장의 코사인 유사도:\", similarity)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ttg7ObG1MppY","executionInfo":{"status":"ok","timestamp":1713528703491,"user_tz":-540,"elapsed":445,"user":{"displayName":"Yubeen Lee","userId":"01212685212812926822"}},"outputId":"dfb964d5-5810-40c3-a211-3a6aab549a18"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["첫 번째 문장과 두 번째 문장의 코사인 유사도: 0.9074012\n"]}]}]}